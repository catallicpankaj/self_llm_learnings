{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf95b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac03aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b05563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is prompt engineering?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aaf6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is the process of designing and crafting high-quality input prompts to elicit specific, accurate, and relevant responses from AI models, such as language models or chatbots. The goal of prompt engineering is to optimize the performance of these models by carefully selecting the right words, phrases, and structures to get the desired output.\n",
      "\n",
      "Prompt engineering involves understanding how AI models process and respond to input prompts, including their strengths, weaknesses, and limitations. It requires a deep understanding of natural language processing (NLP), linguistics, and cognitive psychology, as well as expertise in the specific application domain.\n",
      "\n",
      "Effective prompt engineering involves several key steps:\n",
      "\n",
      "1. **Understanding the task**: Clearly defining the task or goal of the AI model, including what output is desired and what data is available.\n",
      "2. **Analyzing the model**: Studying the capabilities, limitations, and biases of the AI model to determine the most effective prompts.\n",
      "3. **Crafting the prompt**: Designing a well-structured, concise, and clear input prompt that elicits the desired response from the model.\n",
      "4. **Testing and refining**: Iteratively testing and refining the prompt to ensure it produces accurate and relevant outputs.\n",
      "\n",
      "Prompt engineering has become increasingly important as AI models become more prevalent and widely adopted. By optimizing prompts, developers can:\n",
      "\n",
      "1. **Improve accuracy**: Reduce errors and improve the overall quality of responses from AI models.\n",
      "2. **Increase efficiency**: Streamline workflows and reduce the time required to achieve desired outcomes.\n",
      "3. **Enhance user experience**: Create more engaging and effective interactions between users and AI systems.\n",
      "\n",
      "The field of prompt engineering is still evolving, with new research and advancements being made regularly. As AI technology continues to advance, prompt engineering will play an increasingly critical role in optimizing these models for real-world applications.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = requests.post(OLLAMA_API, headers=HEADERS, json=payload, stream=True)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddceb218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
