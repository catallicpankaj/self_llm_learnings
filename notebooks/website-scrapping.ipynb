{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52fe1ef",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../resources/Pankajtechblogs.png\" alt=\"Pankaj Tech Blogs\" width=\"320\"/>\n",
    "</p>\n",
    "\n",
    "# Welcome to the first notebook\n",
    "\n",
    "## What are we going to achieve and learn here\n",
    "\n",
    "This notebook tells us how to scrape the text content from a website using Python (we will use a existing library here), then summarize that content using OpenAI's GPT model. It covers:\n",
    "\n",
    "- Importing required libraries for web requests, HTML parsing, environment management, and OpenAI API access.\n",
    "- Loading the OpenAI API key from environment variables.\n",
    "- Defining a class to fetch and extract text from a given website URL.\n",
    "- Displaying the scraped text in a Jupyter notebook.\n",
    "- Sending the website content to an OpenAI GPT model with a custom prompt to generate a concise, markdown-formatted summary.\n",
    "- Displaying the generated summary in the notebook.\n",
    "- The workflow is: scrape → display raw text → summarize with LLM → display summary.\n",
    "- As an example I will use my own tech blogs website - https://pankajtechblogs.dev/ - please feel free to visit if not done yet. :)\n",
    "\n",
    "<p>\n",
    "  <img src=\"../resources/highlevel-idea-website-summarization.png\" alt=\"High Level Design\" width=\"320\"/>\n",
    "</p>\n",
    "\n",
    "*As first step - let's import the necessary Python libraries and packages that will assist us throughout our code.*\n",
    "\n",
    "**Brief summary of what we gonna use:**\n",
    "\n",
    "- **os:** Provides functions to interact with the operating system, such as reading environment variables or file paths.\n",
    "\n",
    "- **requests:** Allows you to send HTTP requests easily, useful for fetching data from web APIs or websites.\n",
    "\n",
    "- **dotenv.load_dotenv:** Loads environment variables from a .env file into your environment, often used for managing secrets like API keys.\n",
    "\n",
    "- **bs4.BeautifulSoup:** Parses and extracts data from HTML or XML documents, commonly used for web scraping.\n",
    "\n",
    "- **IPython.display.display, Markdown:** Lets you display rich content (like formatted Markdown) directly in Jupyter notebooks.\n",
    "\n",
    "- **openai.OpenAI:** Provides access to the OpenAI API, enabling you to interact with models like GPT for tasks such as text generation or summarization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921aa085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d62e4",
   "metadata": {},
   "source": [
    "Now Next step is to connect with OpenAI, remember to setup your own personal OPENAI_API_KEY in the env vars, to connect to frontier models, here we will use the gpt-4o-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138a0a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"No API key was found\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d485f",
   "metadata": {},
   "source": [
    "Lets talk to OpenAI model and get started with our first prompt message.\n",
    "\n",
    "We will pass the message as shown below. And hit openai.chat.completions api to retrieve the response from the mentioned LLM model. \n",
    "\n",
    "Now if you notice we have passed certain arguments here, let me explain each of them and their usage. \n",
    "\n",
    "model: defines which llm model to use, as there are variety of LLM Models available.\n",
    "\n",
    "messages: this is an object which defines the conversation history between the user and the assistant (model). Each message object has a role (\"user\", \"assistant\" or \"system\") and content (usually the text message which we want to send to the model usually known as Prompt.)\n",
    "\n",
    "This structure allows you to provide context to the model, so it can generate responses that are relevant to the ongoing conversation. For example:\n",
    "```\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm good, how can I help you?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me scrape a website?\"}\n",
    "]\n",
    "```\n",
    "In the below snippet, we are passing a single user message, but we can also include multiple messages to give the model more context about the conversation.\n",
    "\n",
    "temperature: controls the randomness or creativity of the model’s responses (varies from 0-1). A lower value (ex: 0.2) makes the output more focused and deterministic, while a higher value (ex: 0.8) makes it \n",
    "more random and creative.\n",
    "\n",
    "max_tokens: sets the maximum number of tokens (words or word pieces) in the generated response. It limits how long the model’s reply can be. For ex:  max_tokens=150 means the response will not exceed 150 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6608efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! I can help you with the general steps\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello GPT, I want to scrape a website and get the text from it. Can you help me with that?\"\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    "    max_tokens=10,\n",
    "    temperature=0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb8d90",
   "metadata": {},
   "source": [
    "Now lets define a function that will \n",
    "  1. Take a URL as input\n",
    "  2. Sends a HTTP GET request to retrieve the webpage\n",
    "  3. Parses the HTML content using BeautifulSoup python library which we just imported above\n",
    "  4. Then extracts all the text from the page\n",
    "  5. Returns it. \n",
    "\n",
    "And if there is an error during the request, it prints an error message and returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b844c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class WebsiteScraper:\n",
    "    def __init__(self, url):\n",
    "        try:\n",
    "            self.url = url\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            content = soup.get_text()\n",
    "            self.content = content\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching the website: {e}\")\n",
    "            self.content = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b2dd3",
   "metadata": {},
   "source": [
    "Now lets write a function that will display the text and here we define it as display_text(text). Which is self explanatory. \n",
    "\n",
    "Now define a main function that calls the get_website_text function defined above in the class, and output of get_website_text is passed to the display_text function that we just created, that will help to Markdown in the notebook. \n",
    "\n",
    "if name == \"main\": This block ensures that main() runs only when the script is executed directly (not imported as a module). After running main, it prints completion and help messages for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89e1e8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "pankajtechblogsHomepageOpen in appSign inGet startedPankaj Tech BlogsSharing the learningsFollowFollowingOrder Processing System — using Event Driven ArchitectureOrder Processing System — using Event Driven Architecture1. IntroductionPankaj SharmaMar 13Hubble Observability with Cilium — KubernetesHubble Observability with Cilium — KubernetesIn continuation with the previous blog on Zero Trust Networking with Cilium on Kubernetes, let us see how we can establish observability…Pankaj SharmaApr 11, 2024Cilium Network Policy (CNP)—Zero Trust Networking — KubernetesCilium Network Policy (CNP)—Zero Trust Networking — KubernetesNetworking is at the heart of Kubernetes (K8s). When it comes to the connectivity, we need to look forward at the 4 typical use cases (as…Pankaj SharmaApr 11, 2024Spring cloud config server — Auto reload config properties — zero-touchSpring cloud config server — Auto reload config properties — zero-touchIn a distributed system, Spring Cloud Config provides server-side and client-side support for externalized configuration.Pankaj SharmaSep 4, 2023JWT validation — Single Usage — One-time validJWT validation — Single Usage — One-time validSigned JSON Web Token (JWT) is an industry-standard method for exchanging claims securely between two parties. And for…Pankaj SharmaAug 21, 2023Split-key encryption- Securing the data at restSplit-key encryption- Securing the data at restPankaj SharmaAug 17, 2022Disaster Recovery Strategies for Cloud ApplicationsDisaster Recovery Strategies for Cloud ApplicationsWhen we talk about Disaster Recovery aka DR, as a first thought we always think for multi-region replication of workloads. This is true to…Pankaj SharmaJan 25, 2022Database per service — Microservices Design PatternDatabase per service — Microservices Design PatternAny enterprise application will need to persist data in some or another way. For temporary purposes maybe it uses the Cache layer, and for…Pankaj SharmaAug 1, 2021Cloud Migration Strategy — On-Premises to CloudCloud Migration Strategy — On-Premises to CloudLet’s discuss — what is the cloud migration strategy to move the on-prem resources/servers/applications/systems to the cloud.Pankaj SharmaJul 25, 2021Spring Boot Application Monitoring using Prometheus + GrafanaSpring Boot Application Monitoring using Prometheus + GrafanaPankaj SharmaJul 19, 2021Why to use Circuit Breaker Pattern? — Microservices Design PatternWhy to use Circuit Breaker Pattern? — Microservices Design PatternIn the microservices architecture, multiple services are deployed onto the cluster(s), and these services may have Inter-service…Pankaj SharmaJul 16, 2021How to edit an Apigee Proxy?How to edit an Apigee Proxy?Welcome back, this is a continuation of my previous blog —  https://iampankajsharma.medium.com/how-to-create-apigee-api-proxy-219fa2df1425Pankaj SharmaJul 10, 2021How to create Apigee API Proxy?How to create Apigee API Proxy?Welcome back, this is a continuation of my previous blog — https://iampankajsharma.medium.com/why-to-use-an-api-gateway-b36c9988f581Pankaj SharmaJul 10, 2021Why to use an API Gateway?Why to use an API Gateway?Gateway — Chowkidaar (in the Hindi language), that will look after our home for safety and protecting us in some way. Homes in technical…Pankaj SharmaJul 8, 2021About pankajtechblogsLatest StoriesArchiveAbout MediumTermsPrivacyTeams"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "You can now use the text from the website. \n",
      " If you need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "def display_text(text):\n",
    "    if text:\n",
    "        display(Markdown(text))\n",
    "    else:\n",
    "        print(\"No text to display.\")\n",
    "\n",
    "def main():\n",
    "    url = \"https://pankajtechblogs.dev/\"\n",
    "    website_data = WebsiteScraper(url)\n",
    "    display_text(website_data.content)\n",
    "    return website_data.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"Done!\")\n",
    "    print(\"You can now use the text from the website. \\n If you need further assistance, feel free to ask!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1c853",
   "metadata": {},
   "source": [
    "Now whatever content is scrapped we will pass it to our LLM model to generate a nice summary for it. \n",
    "\n",
    "As we already discussed above that we interact with LLM using some instructions that are to be passed in a particular way. \n",
    "\n",
    "**SystemPrompt** - tells models what task they have to perform and what tone they should use, like business, formal, funny etc. \n",
    "\n",
    "**UserPrompt** - Conversation start that user provides.\n",
    "\n",
    "Lets us define each of them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41098ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be related to navigation or links. \\\n",
    "Response should be in markdown.\"\n",
    "\n",
    "def user_prompt_for(website_text):\n",
    "    user_prompt = \"You are looking at a website\\nThe contents of this website is as follows \\n \\\n",
    "please provide a short summary of this website in markdown. \\n\"\n",
    "    user_prompt += website_text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4656756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website\n",
      "The contents of this website is as follows \n",
      " please provide a short summary of this website in markdown. \n",
      "pankajtechblogsHomepageOpen in appSign inGet startedPankaj Tech BlogsSharing the learningsFollowFollowingOrder Processing System — using Event Driven ArchitectureOrder Processing System — using Event Driven Architecture1. IntroductionPankaj SharmaMar 13Hubble Observability with Cilium — KubernetesHubble Observability with Cilium — KubernetesIn continuation with the previous blog on Zero Trust Networking with Cilium on Kubernetes, let us see how we can establish observability…Pankaj SharmaApr 11, 2024Cilium Network Policy (CNP)—Zero Trust Networking — KubernetesCilium Network Policy (CNP)—Zero Trust Networking — KubernetesNetworking is at the heart of Kubernetes (K8s). When it comes to the connectivity, we need to look forward at the 4 typical use cases (as…Pankaj SharmaApr 11, 2024Spring cloud config server — Auto reload config properties — zero-touchSpring cloud config server — Auto reload config properties — zero-touchIn a distributed system, Spring Cloud Config provides server-side and client-side support for externalized configuration.Pankaj SharmaSep 4, 2023JWT validation — Single Usage — One-time validJWT validation — Single Usage — One-time validSigned JSON Web Token (JWT) is an industry-standard method for exchanging claims securely between two parties. And for…Pankaj SharmaAug 21, 2023Split-key encryption- Securing the data at restSplit-key encryption- Securing the data at restPankaj SharmaAug 17, 2022Disaster Recovery Strategies for Cloud ApplicationsDisaster Recovery Strategies for Cloud ApplicationsWhen we talk about Disaster Recovery aka DR, as a first thought we always think for multi-region replication of workloads. This is true to…Pankaj SharmaJan 25, 2022Database per service — Microservices Design PatternDatabase per service — Microservices Design PatternAny enterprise application will need to persist data in some or another way. For temporary purposes maybe it uses the Cache layer, and for…Pankaj SharmaAug 1, 2021Cloud Migration Strategy — On-Premises to CloudCloud Migration Strategy — On-Premises to CloudLet’s discuss — what is the cloud migration strategy to move the on-prem resources/servers/applications/systems to the cloud.Pankaj SharmaJul 25, 2021Spring Boot Application Monitoring using Prometheus + GrafanaSpring Boot Application Monitoring using Prometheus + GrafanaPankaj SharmaJul 19, 2021Why to use Circuit Breaker Pattern? — Microservices Design PatternWhy to use Circuit Breaker Pattern? — Microservices Design PatternIn the microservices architecture, multiple services are deployed onto the cluster(s), and these services may have Inter-service…Pankaj SharmaJul 16, 2021How to edit an Apigee Proxy?How to edit an Apigee Proxy?Welcome back, this is a continuation of my previous blog —  https://iampankajsharma.medium.com/how-to-create-apigee-api-proxy-219fa2df1425Pankaj SharmaJul 10, 2021How to create Apigee API Proxy?How to create Apigee API Proxy?Welcome back, this is a continuation of my previous blog — https://iampankajsharma.medium.com/why-to-use-an-api-gateway-b36c9988f581Pankaj SharmaJul 10, 2021Why to use an API Gateway?Why to use an API Gateway?Gateway — Chowkidaar (in the Hindi language), that will look after our home for safety and protecting us in some way. Homes in technical…Pankaj SharmaJul 8, 2021About pankajtechblogsLatest StoriesArchiveAbout MediumTermsPrivacyTeams\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(WebsiteScraper(\"https://pankajtechblogs.dev/\").content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0525aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Pankaj Tech Blogs\n",
       "\n",
       "Pankaj Tech Blogs is a platform where Pankaj Sharma shares insights and learnings on various technology topics, primarily focusing on software development and cloud computing. The blog features a range of articles covering:\n",
       "\n",
       "- **Event Driven Architecture**: Discussing order processing systems.\n",
       "- **Kubernetes**: Exploring observability with Cilium and implementing Zero Trust Networking.\n",
       "- **Spring Cloud**: Providing guidance on auto-reloading configuration properties in distributed systems.\n",
       "- **Security**: Covering JWT validation and split-key encryption for data protection.\n",
       "- **Disaster Recovery**: Strategies for cloud applications and multi-region workload replication.\n",
       "- **Microservices**: Discussing design patterns like database per service and the circuit breaker pattern.\n",
       "- **Cloud Migration**: Strategies for transitioning from on-premises to cloud environments.\n",
       "- **Monitoring**: Techniques for monitoring Spring Boot applications using Prometheus and Grafana.\n",
       "- **API Management**: Instructions on creating and editing Apigee API proxies.\n",
       "\n",
       "The blog serves as a resource for developers and IT professionals looking to enhance their knowledge in these areas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Here is the summary. \n",
      " If you need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "def messages_for(website_text):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website_text)}\n",
    "    ]\n",
    "\n",
    "def summarize(url):\n",
    "    website = WebsiteScraper(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website.content),\n",
    "        max_tokens=1000,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "    \n",
    "\n",
    "display_summary(\"https://pankajtechblogs.dev/\")\n",
    "print(\"Done!\")\n",
    "print(\"Here is the summary. \\n If you need further assistance, feel free to ask!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f3e76",
   "metadata": {},
   "source": [
    "> Above summary was generated by LLM Model.\n",
    "\n",
    "# **Well, now that we learnt some cool stuff :-)**\n",
    "\n",
    "### Lets also see the practical business use cases for the workflow demonstrated in this notebook:\n",
    "\n",
    "**Content Summarization:**\n",
    "Automatically summarize long articles, reports, or web pages for newsletters, executive briefs, or dashboards.\n",
    "\n",
    "**Market & Competitor Monitoring:**\n",
    "Scrape competitor websites or industry news portals and generate concise summaries for market intelligence.\n",
    "\n",
    "**Customer Support:**\n",
    "Summarize FAQ pages, documentation, or support forums to provide quick answers to customer queries.\n",
    "\n",
    "**Research Automation:**\n",
    "Aggregate and summarize research papers, blogs, or news articles for analysts or researchers.\n",
    "\n",
    "**SEO & Content Curation:**\n",
    "Curate and summarize trending topics or blog posts for content marketing and SEO teams.\n",
    "\n",
    "**Internal Knowledge Management:**\n",
    "Scrape and summarize internal wikis, policy documents, or meeting notes for easy reference.\n",
    "\n",
    "**Regulatory & Compliance Monitoring:**\n",
    "Summarize updates from regulatory bodies’ websites to keep compliance teams informed.\n",
    "\n",
    "**Product/Service Monitoring:**\n",
    "Track and summarize reviews or feedback from product pages or forums.\n",
    "\n",
    "This AI workflow saves time, improves information accessibility, and enables faster, data-driven decision-making across various business functions including some of the above ones. \n",
    "\n",
    "\n",
    "### Thanks for staying with me till here. Happy Learnings. Let's DIY (Do it yourself...)..!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272464c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
